{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRuwwRDaxBCT",
        "outputId": "61433a7c-c2d8-4e36-af3a-5320dc8866a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb langchain google-generativeai langchain-google-genai tiktoken huggingface_hub -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community -U -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7vZ-vVi0c0-",
        "outputId": "d248a9b8-c454-4882-8e74-5c65c9dcd27e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import chromadb\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "import uuid\n"
      ],
      "metadata": {
        "id": "Czqq62_Mx8Kc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Gemini LLM inside LangChain"
      ],
      "metadata": {
        "id": "ZzjdiYuSa-yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=\"AIzaSyDaRiyWPe-17q9XJa5iMB8Vol4aDS9v8Y8\")\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    google_api_key=\"AIzaSyDaRiyWPe-17q9XJa5iMB8Vol4aDS9v8Y8\",\n",
        "    temperature=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "9oFf1AhW0jSX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import the zipfile module"
      ],
      "metadata": {
        "id": "spT7gki-bF8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_path = '/content/asha-bot(1).zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/asha-bot(1)')"
      ],
      "metadata": {
        "id": "WV5iuZvA07uJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk('/content/asha-bot'):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n"
      ],
      "metadata": {
        "id": "5ylW3TTb1APw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load job listings CSV and JSON"
      ],
      "metadata": {
        "id": "z6NGtZDMbLbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "jobs_df = pd.read_csv('/content/asha-bot(1)/asha-bot/job_listing_data.csv')\n",
        "\n",
        "\n",
        "with open('/content/asha-bot(1)/asha-bot/session_details.json', 'r') as f:\n",
        "    sessions_data = json.load(f)\n"
      ],
      "metadata": {
        "id": "MW54kZsM1bUU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load FAQs JSON"
      ],
      "metadata": {
        "id": "2lZnWHMpbRvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/asha-bot(1)/asha-bot/faqs.json', 'r') as f:\n",
        "    faqs_data = json.load(f)\n"
      ],
      "metadata": {
        "id": "zHBur3mY1cuF"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(jobs_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3ENhvY71iwM",
        "outputId": "592c2eb6-2dc7-4903-a347-ab6c5c148e43"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['job_id', 'job_title', 'job_description']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check what fields are present inside sessions_data"
      ],
      "metadata": {
        "id": "7aPWUBCAbZAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(sessions_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiuXTavY2Gme",
        "outputId": "6274f0e9-f518-490a-f0ef-767948245ec6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'session_id': 'sess_001', 'title': 'Leadership for Women', 'description': 'Strategies for women aspiring to leadership roles.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "_SIuf8dSbeox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "jobs_df = pd.read_csv('/content/asha-bot(1)/asha-bot/job_listing_data.csv')\n",
        "\n",
        "\n",
        "with open('/content/asha-bot(1)/asha-bot/session_details.json', 'r') as f:\n",
        "    sessions_data = json.load(f)\n",
        "\n",
        "\n",
        "with open('/content/asha-bot(1)/asha-bot/faqs.json', 'r') as f:\n",
        "    faqs_data = json.load(f)\n"
      ],
      "metadata": {
        "id": "fp5iDnk23K9q"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = []\n",
        "\n",
        "\n",
        "for idx, row in jobs_df.iterrows():\n",
        "    text_data.append(\n",
        "        f\"Job ID: {row['job_id']}\\nJob Title: {row['job_title']}\\nDescription: {row['job_description']}\"\n",
        "    )\n",
        "\n",
        "\n",
        "for session in sessions_data:\n",
        "    text_data.append(\n",
        "        f\"Session Title: {session['title']}\\nSession ID: {session['session_id']}\\nDescription: {session['description']}\"\n",
        "    )\n",
        "\n",
        "\n",
        "for faq in faqs_data:\n",
        "    text_data.append(\n",
        "        f\"FAQ Question: {faq['question']}\\nFAQ Answer: {faq['answer']}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "WLe8nL1Y31rb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split into small documents"
      ],
      "metadata": {
        "id": "ikYxs8MqbnUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding using Huggingface free model"
      ],
      "metadata": {
        "id": "dzY66Nd0bsvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving to ChromaDB"
      ],
      "metadata": {
        "id": "hi2uVGvDbvb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "documents = text_splitter.create_documents(text_data)\n",
        "\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "persist_directory = '/content/asha-chroma'\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "retriever = vectordb.as_retriever()\n"
      ],
      "metadata": {
        "id": "VJrMjakj35pU"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever\n",
        ")\n"
      ],
      "metadata": {
        "id": "_dtrI30K4IwE"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_bias(user_query):\n",
        "    bias_keywords = [\"women can't\", \"female leadership bad\", \"only men can\", \"men are better\", \"are women weak\"]\n",
        "    if any(keyword in user_query.lower() for keyword in bias_keywords):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def handle_bias(user_query):\n",
        "    return \"Empowering women across industries is essential! 🌟 Let's explore inspiring success stories together.\"\n"
      ],
      "metadata": {
        "id": "OZDFqKHE4LJg"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_context = {}\n",
        "\n",
        "def get_session_id():\n",
        "    return str(uuid.uuid4())\n"
      ],
      "metadata": {
        "id": "qwHHZ_3R4OFW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def asha_bot(user_query, session_id=None):\n",
        "    if not session_id:\n",
        "        session_id = get_session_id()\n",
        "\n",
        "    if detect_bias(user_query):\n",
        "        bot_response = handle_bias(user_query)\n",
        "    else:\n",
        "        bot_response = qa_chain.run(user_query)\n",
        "\n",
        "    if session_id not in session_context:\n",
        "        session_context[session_id] = []\n",
        "    session_context[session_id].append({\"user\": user_query, \"bot\": bot_response})\n",
        "\n",
        "    return bot_response, session_id\n"
      ],
      "metadata": {
        "id": "LXImXPTT4Qqj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Show me leadership sessions for women.\"\n",
        "response, session_id = asha_bot(query)\n",
        "\n",
        "print(f\"Session ID: {session_id}\")\n",
        "print(f\"Bot Response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtV8gEsk4UHX",
        "outputId": "5c80f27e-8864-4a27-dd60-84565f80b3ba"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session ID: 4b7e3597-4e8d-4031-aeec-087654e75ad8\n",
            "Bot Response: Leadership for Women (sess_001): Strategies for women aspiring to leadership roles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"Are women bad at leadership?\"\n",
        "response2, session_id2 = asha_bot(query2)\n",
        "\n",
        "print(f\"Session ID: {session_id2}\")\n",
        "print(f\"Bot Response: {response2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xuqB9Bt4ili",
        "outputId": "6335a6fd-f774-4bca-c3ad-51f9929b35d9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session ID: 561b7c7b-93fe-44f2-a759-4b08717d5739\n",
            "Bot Response: The provided text focuses on strategies for women aspiring to leadership roles, but doesn't offer information to suggest whether women are bad at leadership.  Therefore, I cannot answer your question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7weSZc1D47-r",
        "outputId": "6866f33e-4a84-4637-8610-c1cb7571e164"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the real app.py file inside Colab\n",
        "streamlit_code = '''\n",
        "import streamlit as st\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import json\n",
        "import chromadb\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Configure Gemini API\n",
        "genai.configure(api_key=\"AIzaSyAG1o_3LIFtEpsmHrxqBF5p0arw3o8RsT4\")  # <-- Replace with your real Gemini API Key\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    google_api_key=\"AIzaSyAG1o_3LIFtEpsmHrxqBF5p0arw3o8RsT4\",\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "# Load your data\n",
        "jobs_df = pd.read_csv('./data/job_listing_data.csv')\n",
        "\n",
        "with open('./data/session_details.json', 'r') as f:\n",
        "    sessions_data = json.load(f)\n",
        "\n",
        "with open('./data/faqs.json', 'r') as f:\n",
        "    faqs_data = json.load(f)\n",
        "\n",
        "# Create knowledge text chunks\n",
        "text_data = []\n",
        "\n",
        "# Add jobs\n",
        "for idx, row in jobs_df.iterrows():\n",
        "    text_data.append(f\"Job ID: {row['job_id']}\\nJob Title: {row['job_title']}\\nDescription: {row['job_description']}\")\n",
        "\n",
        "# Add sessions\n",
        "for session in sessions_data:\n",
        "    text_data.append(f\"Session Title: {session['title']}\\nSession ID: {session['session_id']}\\nDescription: {session['description']}\")\n",
        "\n",
        "# Add FAQs\n",
        "for faq in faqs_data:\n",
        "    text_data.append(f\"FAQ Question: {faq['question']}\\nFAQ Answer: {faq['answer']}\")\n",
        "\n",
        "# Text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "documents = text_splitter.create_documents(text_data)\n",
        "\n",
        "# Create vectorstore\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embedding,\n",
        "    persist_directory='./chroma_db'\n",
        ")\n",
        "\n",
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "# Create QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever\n",
        ")\n",
        "\n",
        "# Bias Detection\n",
        "def detect_bias(user_query):\n",
        "    bias_keywords = [\"women can't\", \"female leadership bad\", \"only men can\", \"men are better\", \"are women weak\"]\n",
        "    if any(keyword in user_query.lower() for keyword in bias_keywords):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def handle_bias(user_query):\n",
        "    return \"🌟 Women have consistently demonstrated excellence in leadership, innovation, and collaboration across all industries!\"\n",
        "\n",
        "# Session Context Storage\n",
        "session_context = {}\n",
        "\n",
        "def get_session_id():\n",
        "    return str(uuid.uuid4())\n",
        "\n",
        "def asha_bot(user_query, session_id=None):\n",
        "    if not session_id:\n",
        "        session_id = get_session_id()\n",
        "\n",
        "    if detect_bias(user_query):\n",
        "        bot_response = handle_bias(user_query)\n",
        "    else:\n",
        "        bot_response = qa_chain.run(user_query)\n",
        "\n",
        "    if session_id not in session_context:\n",
        "        session_context[session_id] = []\n",
        "    session_context[session_id].append({\"user\": user_query, \"bot\": bot_response})\n",
        "\n",
        "    return bot_response, session_id\n",
        "\n",
        "# ========== Streamlit Frontend ==========\n",
        "\n",
        "st.set_page_config(page_title=\"🌟 Asha - Women's Career Assistant\", page_icon=\"✨\")\n",
        "\n",
        "st.title(\"🌟 Asha Bot - Empowering Women's Careers\")\n",
        "\n",
        "st.write(\"Welcome! Ask me about job opportunities, mentorship sessions, career events, FAQs, and more.\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "if prompt := st.chat_input(\"How can I assist you today?\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    bot_response, session_id = asha_bot(prompt)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(bot_response)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_response})\n",
        "'''\n",
        "\n",
        "# Save it to a file called app.py\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "print(\"✅ Real app.py created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcvY3IOY76uj",
        "outputId": "fa6afc8b-5bae-47e7-9a2e-52eb88f8274a"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Real app.py created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2ADPTfY810P",
        "outputId": "b7d00971-968a-4d6e-efb5-b6266b3d9aeb"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SET YOUR AUTHTOKEN HERE"
      ],
      "metadata": {
        "id": "j_v86VAAb6rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"2wHLF1VyHSUAhx2HzmbmSIV3QHo_7CnrgSAe95jauCmQMjriU\")\n"
      ],
      "metadata": {
        "id": "zaaxLlMWAqGc"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill streamlit\n"
      ],
      "metadata": {
        "id": "c7AHgdWththp"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n"
      ],
      "metadata": {
        "id": "OJY5Q4YRnoNo"
      },
      "execution_count": 118,
      "outputs": []
    }
  ]
}